{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFEpHz9q2TkF"
   },
   "source": [
    "# ChildGPT-3_BiClActPsv\n",
    "https://www.kaggle.com/baekseungyun/gpt-2-with-huggingface-pytorch<br>\n",
    "\n",
    "\n",
    "***troubleshooting***\n",
    "\n",
    "https://github.com/jeffheaton/t81_558_deep_learning\n",
    "\n",
    "https://www.youtube.com/watch?v=VEDy-c5Sk8Y\n",
    "\n",
    "https://www.youtube.com/watch?v=o4-bI_iZKPA\n",
    "\n",
    "https://github.com/jeffheaton/app_deep_learning/blob/main/install/pytorch-install-aug-2023.ipynb\n",
    "\n",
    "https://www.linkedin.com/pulse/how-use-gpu-tensorflow-pytorch-libraries-macbook-pro-m2apple-kashyap\n",
    "\n",
    "https://medium.com/mlearning-ai/mac-m1-m2-gpu-support-in-pytorch-a-step-forward-but-slower-than-conventional-nvidia-gpu-40be9293b898\n",
    "\n",
    "https://developer.apple.com/metal/pytorch/\n",
    "\n",
    "https://www.youtube.com/watch?v=Zx2MHdRgAIc\n",
    "\n",
    "https://youtube.com/watch?v=mS2X1QmIUCI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hv2_wH8A2TkN"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import os\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "from transformers import set_seed, GPT2LMHeadModel, PreTrainedTokenizerFast, GPT2ForSequenceClassification, GPT2Config\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, RandomSampler, SequentialSampler, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from accelerate import init_empty_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12102,
     "status": "ok",
     "timestamp": 1674739750084,
     "user": {
      "displayName": "Humanities.Research.Institute AjouUniv",
      "userId": "03100970392587984879"
     },
     "user_tz": -540
    },
    "id": "9LAZ1CSc3Bm_",
    "outputId": "e9e0945f-109e-461e-e3ca-0cb5e21446ac",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### GPU check\n",
    "\n",
    "# If there's GPU available...\n",
    "print(torch.__version__)\n",
    "\n",
    "print(\"mps available?\", torch.backends.mps.is_available())\n",
    "print(\"mps built?\", torch.backends.mps.is_built())\n",
    "print(\"CUDA enabled?\", torch.cuda.is_available())\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "\n",
    "    # let PyTorch use GPU\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device = mps_device)\n",
    "    print (x)\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Get the GPU device name.\n",
    "device_name = tf.test.gpu_device_name()\n",
    "print(device_name)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "li9QWpubgHQ4"
   },
   "outputs": [],
   "source": [
    "### Parameter setting\n",
    "setEpoch = 10\n",
    "setLearningRate = [0.001, 0.0001]\n",
    "setBatch = [16, 64]\n",
    "setMaxLength = [64, 256]\n",
    "setPatching = [0, 0.25, 0.50, 0.75, 1]\n",
    "setFineTuning = [0.25, 0.50, 0.75, 1]\n",
    "\n",
    "setEpsilon = 1e-8\n",
    "setSeed = 42\n",
    "labelNumber = 2\n",
    "setTry = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5d1Dh7RDY2SE",
    "outputId": "ac670b90-39ae-418b-af75-1f1839d42dc2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(torch.mps.current_allocated_memory)\n",
    "#print(torch.mps.driver_allocated_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzYiy25-Y2SF"
   },
   "outputs": [],
   "source": [
    "#PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UmKXbu2UY2SF",
    "outputId": "765d43c6-dd8a-4981-81c5-5d0f6f6f4ab5"
   },
   "outputs": [],
   "source": [
    "### Modelling\n",
    "\n",
    "for currentLearningRate in setLearningRate:\n",
    "\n",
    "    for currentBatch in setBatch:\n",
    "\n",
    "        for currentMaxLength in setMaxLength:\n",
    "            \n",
    "            for currentPatching in setPatching:\n",
    "                \n",
    "                for currentFineTuning in setFineTuning:\n",
    "\n",
    "                    for currentTry in range(1,setTry):\n",
    "\n",
    "                        ### 1. load model & tokeniser (https://github.com/SKT-AI/KoGPT2)\n",
    "\n",
    "                        tokenizer = AutoTokenizer.from_pretrained(\n",
    "                            'kakaobrain/kogpt', revision='KoGPT6B-ryan1.5b', #revision='KoGPT6B-ryan1.5b-float16',  # or float32 version: revision=KoGPT6B-ryan1.5b\n",
    "                            bos_token='[BOS]', eos_token='[EOS]', unk_token='[UNK]', pad_token='[PAD]', mask_token='[MASK]'\n",
    "                        )\n",
    "                        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "                            'kakaobrain/kogpt', revision='KoGPT6B-ryan1.5b', #revision='KoGPT6B-ryan1.5b-float16',  # or float32 version: revision=KoGPT6B-ryan1.5b\n",
    "                            pad_token_id=tokenizer.eos_token_id, torch_dtype='auto', low_cpu_mem_usage=True).to(device='mps', non_blocking=True)\n",
    "                        _ = model.eval()\n",
    "\n",
    "                        tokenizer.padding_side = \"left\" # Very Important\n",
    "                        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "                        print(\"Before patching: \",len(tokenizer.get_vocab()))\n",
    "\n",
    "                        # finetuning pre-trained model using CHILDES\n",
    "                        entireCorpus = \"./Data/CHILDES/CHILDES_ALL.txt\"\n",
    "                        entireFr = open(entireCorpus, 'r')\n",
    "                        entireContents = entireFr.readlines()\n",
    "                        entireFr.close()\n",
    "\n",
    "\n",
    "                        def RandomSelect(dataList, prob):\n",
    "                            dataSize = int(len(dataList) * prob)\n",
    "\n",
    "                            dataListRD = []\n",
    "                            for i in range(0, dataSize):\n",
    "                                randomNum = random.randrange(0, len(dataList))\n",
    "                                dataListRD.append(dataList[randomNum])\n",
    "                                del dataList[randomNum]\n",
    "\n",
    "                            return dataListRD\n",
    "\n",
    "\n",
    "                        entireSet = set()\n",
    "                        entireContentList = list()\n",
    "\n",
    "                        entireContentRD = RandomSelect(entireContents, float(currentPatching))\n",
    "\n",
    "                        for entireContent in entireContentRD:\n",
    "                            entireContent = re.sub('[^가-힣]', ' ', entireContent)\n",
    "                            entireContent = re.sub('[\\s]+', ' ', entireContent)\n",
    "                            entireContentList.append(entireContent.replace(\"\\n\",\"\"))\n",
    "\n",
    "                            entireContentSplit = entireContent.split(\" \")\n",
    "\n",
    "                            for each in entireContentSplit:\n",
    "                                if each != \"\":\n",
    "                                    entireSet.add(each)\n",
    "\n",
    "                        wordDic = {}\n",
    "                        for eachWord in entireSet:\n",
    "                            wordDic[eachWord] = 0\n",
    "\n",
    "                        for contentEach in entireContentList:\n",
    "                            contentEachSplit = contentEach.split(\" \")\n",
    "                            for each in contentEachSplit:\n",
    "                                if each != \"\":\n",
    "                                    wordDic[each] = wordDic[each] + 1\n",
    "\n",
    "                        wordDicSorted = dict(sorted(wordDic.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "                        countNum = 1\n",
    "                        for key, value in wordDicSorted.items():\n",
    "                            if value > 1:\n",
    "                                countNum = countNum + 1\n",
    "                                tokenizer.add_tokens([key])\n",
    "\n",
    "                        print(\"After patching: \",len(tokenizer.get_vocab()))\n",
    "\n",
    "                        model.resize_token_embeddings(len(tokenizer))\n",
    "                        model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "\n",
    "                        ### 2. Build Dataset\n",
    "                        trainCorpus = \"./Data/trainBi_20231107.csv\"\n",
    "                        trainFr = open(trainCorpus, 'r')\n",
    "                        trainContents = trainFr.readlines()\n",
    "                        trainFr.close()\n",
    "\n",
    "                        train_List = []\n",
    "\n",
    "                        #데이터 위의 변수 정보 삭제\n",
    "                        trainVar = trainContents[0]\n",
    "                        del trainContents[0]\n",
    "                        trainContentRD = RandomSelect(trainContents, float(currentFineTuning))\n",
    "\n",
    "                        for eachContent in trainContentRD:\n",
    "                            eachSplit = eachContent.replace(\"\\n\",\"\").split(\",\")\n",
    "                            train_List.append(eachSplit)\n",
    "\n",
    "                        trainPD = pd.DataFrame(train_List)\n",
    "                        trainPD.columns = trainVar.replace(\"\\n\",\"\").split(\",\")\n",
    "\n",
    "\n",
    "\n",
    "                        testCorpus = \"./Data/testBi_20231107.csv\"\n",
    "                        testFr = open(testCorpus, 'r')\n",
    "                        testContents = testFr.readlines()\n",
    "                        testFr.close()\n",
    "\n",
    "                        test_List = []\n",
    "\n",
    "                        #데이터 위의 변수 정보 삭제\n",
    "                        testVar = testContents[0]\n",
    "                        del testContents[0]\n",
    "\n",
    "                        for eachContent in testContents:\n",
    "                            eachSplit = eachContent.replace(\"\\n\",\"\").split(\",\")\n",
    "                            test_List.append(eachSplit)\n",
    "\n",
    "                        testPD = pd.DataFrame(test_List)\n",
    "                        testPD.columns = testVar.replace(\"\\n\",\"\").split(\",\")\n",
    "\n",
    "\n",
    "                        ### 2. Build Dataset\n",
    "\n",
    "                        class Dataset(Dataset):\n",
    "                            def __init__(self, Dtype, dataIn):\n",
    "                                self.Dtype = Dtype\n",
    "                                self.data = dataIn\n",
    "\n",
    "                            def __len__(self):\n",
    "                                return len(self.data)\n",
    "\n",
    "                            def __getitem__(self, index):\n",
    "                                record = self.data.iloc[index]\n",
    "                                text = record['Sentence']\n",
    "                                if self.Dtype == \"train\":\n",
    "                                    return {'Sentence': text, 'label': record['Label']}\n",
    "                                else:\n",
    "                                    return {'Sentence': text, 'label': '0'}\n",
    "\n",
    "                        train_dataset = Dataset(\"train\", trainPD)\n",
    "                        test_dataset = Dataset(\"test\", testPD)\n",
    "\n",
    "\n",
    "\n",
    "                        ### 3. Data Collator\n",
    "\n",
    "                        class Gpt3ClassificationCollator(object):\n",
    "                            def __init__(self, tokenizer, max_seq_len=None):\n",
    "                                self.tokenizer = tokenizer\n",
    "                                self.max_seq_len = max_seq_len\n",
    "\n",
    "                                return\n",
    "\n",
    "                            def __call__(self, sequences):\n",
    "                                texts = [sequence['Sentence'] for sequence in sequences]\n",
    "                                labels = [int(sequence['label']) for sequence in sequences]\n",
    "                                inputs = self.tokenizer(text=texts,\n",
    "                                                        return_tensors='pt',\n",
    "                                                        padding=True,\n",
    "                                                        truncation=True,\n",
    "                                                        max_length=self.max_seq_len)\n",
    "                                inputs.update({'labels': torch.tensor(labels)})\n",
    "\n",
    "                                return inputs\n",
    "\n",
    "                        gpt3classificationcollator = Gpt3ClassificationCollator(tokenizer=tokenizer, max_seq_len=currentMaxLength)\n",
    "\n",
    "\n",
    "                        ### 4. DataLoader\n",
    "\n",
    "                        train_size = int(len(train_dataset) * 0.8)\n",
    "                        val_size = len(train_dataset) - train_size\n",
    "                        train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "                        train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                                                      batch_size=currentBatch,\n",
    "                                                      shuffle=True,\n",
    "                                                      collate_fn=gpt3classificationcollator)\n",
    "                        val_dataloader = DataLoader(dataset=val_dataset,\n",
    "                                                    batch_size=currentBatch,\n",
    "                                                    shuffle=False,\n",
    "                                                    collate_fn=gpt3classificationcollator)\n",
    "                        test_dataloader = DataLoader(dataset=test_dataset,\n",
    "                                                    batch_size=currentBatch,\n",
    "                                                    shuffle=False,\n",
    "                                                    collate_fn=gpt3classificationcollator)\n",
    "\n",
    "\n",
    "                        ### 5. Optimiser & Lr Scheduler\n",
    "\n",
    "                        total_epochs = setEpoch\n",
    "\n",
    "                        param_optimizer = list(model.named_parameters())\n",
    "                        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "                        optimizer_grouped_parameters = [\n",
    "                            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "                            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "                        ]\n",
    "                        optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                                          lr=currentLearningRate,\n",
    "                                          eps=setEpsilon)\n",
    "\n",
    "                        num_train_steps = len(train_dataloader) * total_epochs\n",
    "                        num_warmup_steps = int(num_train_steps * 0.1)\n",
    "\n",
    "                        lr_scheduler = get_cosine_schedule_with_warmup(optimizer,\n",
    "                                                                      num_warmup_steps=num_warmup_steps,\n",
    "                                                                      num_training_steps = num_train_steps)\n",
    "\n",
    "\n",
    "                        ###6. Train & Validation\n",
    "\n",
    "                        def train(dataloader, optimizer, scheduler, device_):\n",
    "                            global model\n",
    "                            model.train()\n",
    "\n",
    "                            prediction_labels = []\n",
    "                            true_labels = []\n",
    "\n",
    "                            total_loss = []\n",
    "\n",
    "                            for batch in dataloader:\n",
    "                                true_labels += batch['labels'].numpy().flatten().tolist()\n",
    "                                batch = {k:v.type(torch.long).to(device_) for k, v in batch.items()}\n",
    "\n",
    "\n",
    "                                outputs = model(**batch)\n",
    "                                loss, logits = outputs[:2]\n",
    "                                logits = logits.detach().cpu().numpy()\n",
    "                                total_loss.append(loss.item())\n",
    "\n",
    "                                optimizer.zero_grad()\n",
    "                                loss.backward()\n",
    "                                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # prevent exploding gradient\n",
    "\n",
    "                                optimizer.step()\n",
    "                                scheduler.step()\n",
    "\n",
    "                                prediction_labels += logits.argmax(axis=-1).flatten().tolist()\n",
    "\n",
    "                            return true_labels, prediction_labels, total_loss\n",
    "\n",
    "                        def validation(dataloader, device_):\n",
    "                            global model\n",
    "                            model.eval()\n",
    "\n",
    "                            prediction_labels = []\n",
    "                            true_labels = []\n",
    "\n",
    "                            embedding_outputs = []\n",
    "\n",
    "                            total_loss = []\n",
    "\n",
    "                            outputs = []\n",
    "\n",
    "                            for batch in dataloader:\n",
    "                                true_labels += batch['labels'].numpy().flatten().tolist()\n",
    "                                batch = {k:v.type(torch.long).to(device_) for k, v in batch.items()}\n",
    "\n",
    "                                with torch.no_grad():\n",
    "                                    outputs = model(**batch)\n",
    "                                    loss, logits = outputs[:2]\n",
    "                                    logits = logits.detach().cpu().numpy()\n",
    "                                    total_loss.append(loss.item())\n",
    "\n",
    "                                    prediction_labels += logits.argmax(axis=-1).flatten().tolist()\n",
    "\n",
    "                                    embedding_outputs += logits.tolist()\n",
    "\n",
    "                                    outputs = outputs\n",
    "\n",
    "                            return true_labels, prediction_labels, total_loss, outputs, embedding_outputs\n",
    "\n",
    "                        def outreault(guess):\n",
    "                            guess = int(guess)\n",
    "                            outConstruction = \"\"\n",
    "                            if guess == 0:\n",
    "                                outConstruction = \"agent-first\"\n",
    "                            elif guess == 1:\n",
    "                                outConstruction = \"theme-first\"\n",
    "\n",
    "                            return outConstruction\n",
    "\n",
    "\n",
    "                        ### 7. Run\n",
    "\n",
    "                        outDir = \"./Output/GPT/gpt3Bi_actpsv_LR\" + str(currentLearningRate) + \"_Batch\" + str(currentBatch) + \"_SL\" + str(currentMaxLength) + \"_PC\" + str(currentPatching) + \"_FT\" + str(currentFineTuning) + \"_T\" + str(currentTry) + \".csv\"\n",
    "                        f = open(outDir, 'w')\n",
    "                        f.write(\"epoch,sentence,originalLabel,predictedLabel,predictedConstruction,result\"+\"\\n\")\n",
    "\n",
    "                        device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "                        model.to(device)\n",
    "\n",
    "                        all_loss = {'train_loss': [], 'val_loss': []}\n",
    "                        all_acc = {'train_acc': [], 'val_acc': []}\n",
    "                        outputs = []\n",
    "\n",
    "                        for epoch in range(total_epochs):\n",
    "\n",
    "                            y, y_pred, train_loss = train(train_dataloader, optimizer, lr_scheduler, device)\n",
    "                            train_acc = accuracy_score(y, y_pred)\n",
    "\n",
    "                            y, y_pred, val_loss, outputs, logits_labels = validation(val_dataloader, device)\n",
    "                            val_acc = accuracy_score(y, y_pred)\n",
    "\n",
    "                            all_loss['train_loss'] += train_loss\n",
    "                            all_loss['val_loss'] += val_loss\n",
    "\n",
    "                            all_acc['train_acc'].append(train_acc)\n",
    "                            all_acc['val_acc'].append(val_acc)\n",
    "\n",
    "                            outputs = outputs\n",
    "\n",
    "                            print('======== Epoch {:} / {:} ========'.format(epoch + 1, total_epochs))\n",
    "                            #print('Training...')\n",
    "\n",
    "                            print(f'Epoch: {epoch}, train_loss: {torch.tensor(train_loss).mean():.3f}, train_acc: {train_acc:.3f}, val_loss: {torch.tensor(val_loss).mean():.3f}, val_acc: {val_acc:.3f}')\n",
    "\n",
    "                            y, y_pred, val_loss, outputs, logits_labels = validation(test_dataloader, device)\n",
    "\n",
    "                            testFileDir = fileDir = \"./Data/testBi_20231107.csv\"\n",
    "                            testFr = open(testFileDir, 'r')\n",
    "                            testContents = testFr.readlines()\n",
    "                            testFr.close()\n",
    "\n",
    "                            test = pd.DataFrame(columns=('Label', 'Sentence'))\n",
    "                            i = 0\n",
    "                            for content in testContents:\n",
    "                                if i == 0:\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    infos = content.split(\",\")\n",
    "                                    label = int(infos[0])\n",
    "                                    sentence = infos[1].replace(\"\\n\", \"\")\n",
    "                                    test.loc[i] = [label, sentence]\n",
    "                                i = i + 1\n",
    "\n",
    "                            test['Sentence'] = test['Sentence'].str.replace(r'[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》\\\\n\\t]+', \" \", regex=True)\n",
    "                            test['Sentence'] = test['Sentence'].str.replace(r'\\t+', \" \", regex=True)\n",
    "                            test['Sentence'] = test['Sentence'].str.replace(r'[\\\\n]+', \" \", regex=True)\n",
    "\n",
    "                            # import test sents\n",
    "                            testSentences = test['Sentence']\n",
    "\n",
    "                            totalNum = 0\n",
    "                            correctNum = 0\n",
    "                            for each in range(0, len(testSentences)):\n",
    "                                #print(test['Label'][each + 1], test['Sentence'][each + 1])\n",
    "                                #print(\"y_pred\", len(y_pred))\n",
    "                                guess = str(y_pred[each])\n",
    "                                if guess == str(test['Label'][each + 1]):\n",
    "                                    #print(\"input: \", test['Sentence'][each + 1], \", predict: \", guess, \"(O)\")\n",
    "                                    f.write(str(epoch+1) + \",\" + test['Sentence'][each + 1] + \",\" + str(test['Label'][each + 1]) + \",\" + guess + \",\" + outreault(guess)+ \",1\" + \"\\n\")\n",
    "                                    correctNum = correctNum + 1\n",
    "                                else:\n",
    "                                    f.write(str(epoch+1) + \",\" + test['Sentence'][each + 1] + \",\" + str(test['Label'][each + 1]) + \",\" + guess + \",\" + outreault(guess) + \",0\" + \"\\n\")\n",
    "                                    #print(\"input: \", test['Sentence'][each + 1], \", predict: \", guess, \"(X)\")\n",
    "                                totalNum = totalNum + 1\n",
    "\n",
    "                            #print(\"totalNum: \", totalNum, \" correctNum: \", correctNum, \" accuracy: \", (correctNum/totalNum))\n",
    "\n",
    "                        f.close()\n",
    "\n",
    "                        print(\"Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuClass": "premium",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
